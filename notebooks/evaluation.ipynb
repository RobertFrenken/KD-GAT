{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e75936",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'graph (Python 3.10.16)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. WebSocket is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np # Successfully installed numpy-1.23.5\n",
    "import pandas as pd # Successfully installed pandas-1.3.5\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split, Subset\n",
    "import torch\n",
    "import sys\n",
    "import time\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import wandb\n",
    "import json\n",
    "from models.models import GATWithJK\n",
    "from preprocessing import graph_creation\n",
    "from training_utils import PyTorchTrainer, PyTorchDistillationTrainer, DistillationTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122ec7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f426a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = GATWithJK(in_channels=10, hidden_channels=32, out_channels=1, num_layers=5, heads=8).to(device)\n",
    "student_model = GATWithJK(in_channels=10, hidden_channels=32, out_channels=1, num_layers=2, heads=4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e09560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            data = data.to(device)\n",
    "            outputs = model(data.x, data.edge_index)\n",
    "            preds = (outputs > 0.5).float()  # Assuming binary classification\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_labels.append(data.y.cpu().numpy())\n",
    "\n",
    "    # Flatten the lists\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cecf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of test datasets and corresponding model weights\n",
    "test_datasets = [\n",
    "    {\"folder\": \"datasets/can-train-and-test-v1.5/set_01\", \n",
    "     \"teacher_weight\": \"saved_models/best_teacher_model_set_01.pth\", \n",
    "     \"student_weight\": \"saved_models/final_student_model_set_01.pth\"},\n",
    "    {\"folder\": \"datasets/can-train-and-test-v1.5/set_02\", \n",
    "     \"teacher_weight\": \"saved_models/best_teacher_model_set_02.pth\", \n",
    "     \"student_weight\": \"saved_models/final_student_model_set_02.pth\"},\n",
    "    {\"folder\": \"datasets/can-train-and-test-v1.5/set_03\", \n",
    "     \"teacher_weight\": \"saved_models/best_teacher_model_set_03.pth\", \n",
    "     \"student_weight\": \"saved_models/final_student_model_set_03.pth\"},\n",
    "    {\"folder\": \"datasets/can-train-and-test-v1.5/set_04\", \"teacher_weight\": \n",
    "     \"saved_models/best_teacher_model_set_04.pth\", \"student_weight\": \n",
    "     \"saved_models/final_student_model_set_04.pth\"},\n",
    "    {\"folder\": \"datasets/can-train-and-test-v1.5/hcrl-ch\", \n",
    "     \"teacher_weight\": \"saved_models/best_teacher_model_ch.pth\", \n",
    "     \"student_weight\": \"saved_models/final_student_model_ch.pth\"},\n",
    "    {\"folder\": \"datasets/can-train-and-test-v1.5/hcrl-sa\", \n",
    "     \"teacher_weight\": \"saved_models/best_teacher_model_hcrl_sa.pth\", \n",
    "     \"student_weight\": \"saved_models/final_student_model_hcrl_sa.pth\"},\n",
    "]\n",
    "\n",
    "# Iterate through each dataset\n",
    "for dataset_info in test_datasets:\n",
    "    root_folder = dataset_info[\"root_folder\"]\n",
    "    teacher_weight = dataset_info[\"teacher_weight\"]\n",
    "    student_weight = dataset_info[\"student_weight\"]\n",
    "\n",
    "    print(f\"Evaluating dataset in root folder: {root_folder}\")\n",
    "\n",
    "    # Load the test dataset using graph_creation\n",
    "    test_dataset = graph_creation(root_folder, folder_type=\"test\")\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    # Load the teacher model\n",
    "    teacher_model.load_state_dict(torch.load(teacher_weight))\n",
    "    teacher_model.eval()\n",
    "\n",
    "    # Load the student model\n",
    "    student_model.load_state_dict(torch.load(student_weight))\n",
    "    student_model.eval()\n",
    "\n",
    "    # Evaluate the teacher model\n",
    "    teacher_metrics = evaluate_model(teacher_model, test_loader, device)\n",
    "    print(f\"Teacher Model - Accuracy: {teacher_metrics[0]:.4f}, Precision: {teacher_metrics[1]:.4f}, Recall: {teacher_metrics[2]:.4f}, F1 Score: {teacher_metrics[3]:.4f}\")\n",
    "\n",
    "    # Evaluate the student model\n",
    "    student_metrics = evaluate_model(student_model, test_loader, device)\n",
    "    print(f\"Student Model - Accuracy: {student_metrics[0]:.4f}, Precision: {student_metrics[1]:.4f}, Recall: {student_metrics[2]:.4f}, F1 Score: {student_metrics[3]:.4f}\")\n",
    "\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
