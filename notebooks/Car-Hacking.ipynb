{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Successfully installed numpy-1.23.5\n",
    "import pandas as pd # Successfully installed pandas-1.3.5\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "# the temporal package is not available TODO: find what the issue is\n",
    "# from torch_geometric_temporal.nn.recurrent import A3TGCN2 # torch-geometric-temporal 0.54.0 requires pandas<=1.3.5, but you have pandas 2.2.3 which is incompatible.\n",
    "#from torch_geometric_temporal.signal import temporal_signal_split\n",
    "# import \n",
    "# Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
    "# from stellargraph import StellarGraph\n",
    "# import custom functions from utils.py\n",
    "# from utils import *\n",
    "# os.getcwd() # double check current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:\\Users\\User1\\Documents\\GitHub\\CAN-Graph\\notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .. goes up one level in directory\n",
    "path = r'../datasets/Car-Hacking Dataset/Fuzzy_dataset.csv'\n",
    "path = r'../datasets/Car-Hacking Dataset/DoS_dataset.csv'\n",
    "path = r'../datasets/Car-Hacking Dataset/gear_dataset.csv'\n",
    "path = r'../datasets/Car-Hacking Dataset/RPM_dataset.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.columns = ['Timestamp', 'CAN ID','DLC','Data1','Data2','Data3','Data4','Data5','Data6','Data7','Data8', 'label'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTemporal graph dataset: a graph that changes over time\\nGraph type: Homogeneous graph\\nNodes: CAN ID\\nEdges: The next CAN ID in the sequence\\nNode Features (optional): The data in the CAN ID\\n\\nSteps:\\n1. identify node properties\\n2. Edges: How to connect nodes?\\n3. Extract labels\\n\\nConvert to pytorch geometric format\\nOne graph to another graph: 200 messages to 1 graph\\n\\nThere is also pytorch geometric temporal package\\n\\n# build a baseline model RF, SVM, etc\\n\\n# fraud datasets may have incorrect labels -> use label smoothing\\nFeatureless nodes: use random numbers\\n\\nmake a GCN that uses labels only, and one that takes an average of data form its neighbors as well\\nGraph Attention Networks (GAT)\\n\\nIdea: could I use FL on the different car datasets, share those weights and perhaps it could generalize better. A practical use case would be between different companies, where they don't want to share their data\\nbut it is in their best interest to have the best performing cybersecurity model.\\n\\nhttps://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.explain.algorithm.GNNExplainer.html\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Temporal graph dataset: a graph that changes over time\n",
    "Graph type: Homogeneous graph\n",
    "Nodes: CAN ID\n",
    "Edges: The next CAN ID in the sequence\n",
    "Node Features (optional): The data in the CAN ID\n",
    "\n",
    "Steps:\n",
    "1. identify node properties\n",
    "2. Edges: How to connect nodes?\n",
    "3. Extract labels\n",
    "\n",
    "Convert to pytorch geometric format\n",
    "One graph to another graph: 200 messages to 1 graph\n",
    "\n",
    "There is also pytorch geometric temporal package\n",
    "\n",
    "# build a baseline model RF, SVM, etc\n",
    "\n",
    "# fraud datasets may have incorrect labels -> use label smoothing\n",
    "Featureless nodes: use random numbers\n",
    "\n",
    "make a GCN that uses labels only, and one that takes an average of data form its neighbors as well\n",
    "Graph Attention Networks (GAT)\n",
    "\n",
    "Idea: could I use FL on the different car datasets, share those weights and perhaps it could generalize better. A practical use case would be between different companies, where they don't want to share their data\n",
    "but it is in their best interest to have the best performing cybersecurity model.\n",
    "\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.explain.algorithm.GNNExplainer.html\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Node'] = df['CAN ID']\n",
    "df['Edge'] = df['CAN ID'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_decimal(x):\n",
    "    if x is None or x == 'None':\n",
    "        return None\n",
    "    try:\n",
    "        return int(x, 16)\n",
    "    except (ValueError, TypeError):\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hex_to_decimal = lambda y: int(y, 16)\n",
    "# Need to encode the strings to integers\n",
    "df = df.apply(lambda x: x.apply(hex_to_decimal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the last row\n",
    "df = df.drop(df.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TimeSeriesGraphDataset(Dataset):\n",
    "    def __init__(self, time_series_data, window_size, stride):\n",
    "        self.data = time_series_data\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.graphs = self._create_graphs()\n",
    "\n",
    "    def _create_graphs(self):\n",
    "        graphs = []\n",
    "        for i in range(0, len(self.data) - self.window_size + 1, self.stride):\n",
    "            window = self.data[i:i+self.window_size]\n",
    "            graph = self.create_single_graph(window)\n",
    "            graphs.append(graph)\n",
    "        return graphs\n",
    "\n",
    "    def create_single_graph(self, window_data):\n",
    "        x = torch.tensor(window_data, dtype=torch.float)\n",
    "        # call the edge index function here\n",
    "        edge_index = self._get_edge_index(window_data)\n",
    "        # last column are the labels\n",
    "        y = torch.tensor(window_data[:, -1], dtype=torch.long)\n",
    "        return Data(x=x, edge_index=edge_index, y=y)\n",
    "    \n",
    "    def _get_edge_index(self, window_data: np.ndarray) -> torch.Tensor:\n",
    "        # Assuming your data is in a list or numpy array called 'data'\n",
    "        nodes = torch.tensor([row[0] for row in window_data], dtype=torch.long)\n",
    "        edges = torch.tensor([row[1] for row in window_data], dtype=torch.long)\n",
    "\n",
    "        edge_index = torch.stack([nodes, edges], dim=0)\n",
    "        # I need to look into the utility of contiguous\n",
    "        # edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "        return edge_index\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.graphs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cProfile\n",
    "# import pstats\n",
    "# import io\n",
    "\n",
    "# # Profile the TimeSeriesGraphDataset creation\n",
    "# pr = cProfile.Profile()\n",
    "# pr.enable()\n",
    "\n",
    "# # Create the TimeSeriesGraphDataset\n",
    "# dataset = TimeSeriesGraphDataset(arr, window_size=50, stride=1)\n",
    "\n",
    "# pr.disable()\n",
    "# s = io.StringIO()\n",
    "# sortby = 'cumulative'\n",
    "# ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "# ps.print_stats()\n",
    "# print(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>CAN ID</th>\n",
       "      <th>DLC</th>\n",
       "      <th>Data1</th>\n",
       "      <th>Data2</th>\n",
       "      <th>Data3</th>\n",
       "      <th>Data4</th>\n",
       "      <th>Data5</th>\n",
       "      <th>Data6</th>\n",
       "      <th>Data7</th>\n",
       "      <th>Data8</th>\n",
       "      <th>label</th>\n",
       "      <th>Node</th>\n",
       "      <th>Edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.478191e+09</td>\n",
       "      <td>399</td>\n",
       "      <td>8</td>\n",
       "      <td>254</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>399</td>\n",
       "      <td>608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.478191e+09</td>\n",
       "      <td>608</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>48.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>R</td>\n",
       "      <td>608</td>\n",
       "      <td>672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.478191e+09</td>\n",
       "      <td>672</td>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>29.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>672</td>\n",
       "      <td>809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.478191e+09</td>\n",
       "      <td>809</td>\n",
       "      <td>8</td>\n",
       "      <td>220</td>\n",
       "      <td>184</td>\n",
       "      <td>126</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>R</td>\n",
       "      <td>809</td>\n",
       "      <td>1349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.478191e+09</td>\n",
       "      <td>1349</td>\n",
       "      <td>8</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>1349</td>\n",
       "      <td>704.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4621695</th>\n",
       "      <td>1.478201e+09</td>\n",
       "      <td>790</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>48</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>R</td>\n",
       "      <td>790</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4621696</th>\n",
       "      <td>1.478201e+09</td>\n",
       "      <td>399</td>\n",
       "      <td>8</td>\n",
       "      <td>254</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>399</td>\n",
       "      <td>608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4621697</th>\n",
       "      <td>1.478201e+09</td>\n",
       "      <td>608</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>48.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>R</td>\n",
       "      <td>608</td>\n",
       "      <td>672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4621698</th>\n",
       "      <td>1.478201e+09</td>\n",
       "      <td>672</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>29.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>R</td>\n",
       "      <td>672</td>\n",
       "      <td>809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4621699</th>\n",
       "      <td>1.478201e+09</td>\n",
       "      <td>809</td>\n",
       "      <td>8</td>\n",
       "      <td>220</td>\n",
       "      <td>183</td>\n",
       "      <td>127</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>R</td>\n",
       "      <td>809</td>\n",
       "      <td>1349.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4621700 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp  CAN ID  DLC  Data1  Data2 Data3  Data4  Data5  Data6  \\\n",
       "0        1.478191e+09     399    8    254     59     0    0.0    0.0   60.0   \n",
       "1        1.478191e+09     608    8     25     34    34   48.0  255.0  143.0   \n",
       "2        1.478191e+09     672    8     96      0   131   29.0  150.0    2.0   \n",
       "3        1.478191e+09     809    8    220    184   126   20.0   17.0   32.0   \n",
       "4        1.478191e+09    1349    8    216      0     0  131.0    0.0    0.0   \n",
       "...               ...     ...  ...    ...    ...   ...    ...    ...    ...   \n",
       "4621695  1.478201e+09     790    8      5     33    48   10.0   33.0   30.0   \n",
       "4621696  1.478201e+09     399    8    254     89     0    0.0    0.0   65.0   \n",
       "4621697  1.478201e+09     608    8     24     33    33   48.0    8.0  143.0   \n",
       "4621698  1.478201e+09     672    8     36      0   154   29.0  151.0    2.0   \n",
       "4621699  1.478201e+09     809    8    220    183   127   20.0   17.0   32.0   \n",
       "\n",
       "         Data7  Data8 label  Node    Edge  \n",
       "0          0.0    0.0     R   399   608.0  \n",
       "1        110.0   63.0     R   608   672.0  \n",
       "2        189.0    0.0     R   672   809.0  \n",
       "3          0.0   20.0     R   809  1349.0  \n",
       "4          0.0    0.0     R  1349   704.0  \n",
       "...        ...    ...   ...   ...     ...  \n",
       "4621695    0.0  111.0     R   790   399.0  \n",
       "4621696    0.0    0.0     R   399   608.0  \n",
       "4621697  109.0   25.0     R   608   672.0  \n",
       "4621698  189.0    0.0     R   672   809.0  \n",
       "4621699    0.0   20.0     R   809  1349.0  \n",
       "\n",
       "[4621700 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'Data3' contains 'R'\n",
    "df_dropped = df[df['Data3'] != 'R']\n",
    "df= df_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User1\\AppData\\Local\\Temp\\ipykernel_16060\\40276460.py:5: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.loc[mask, :] = df.loc[mask, :].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# # Identify rows where 'Data3' contains 'R'\n",
    "# mask = df['Data3'] == 'R'\n",
    "\n",
    "# # Pad these rows with zeros and add 'R' label at the end\n",
    "# df.loc[mask, :] = df.loc[mask, :].fillna(0)\n",
    "# df.loc[mask, 'label'] = 'R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User1\\AppData\\Local\\Temp\\ipykernel_20304\\4091684753.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['label'] = df['label'].replace({'R': 0, 'T': 1})\n",
      "C:\\Users\\User1\\AppData\\Local\\Temp\\ipykernel_20304\\4091684753.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['label'] = df['label'].replace({'R': 0, 'T': 1})\n"
     ]
    }
   ],
   "source": [
    "df['label'] = df['label'].replace({'R': 0, 'T': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User1\\AppData\\Local\\Temp\\ipykernel_20304\\63676179.py:2: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# Replace NaN values with zero\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pad rows with zeros and add 'R' label at the end\n",
    "def pad_row(row):\n",
    "    if row['Data3'] == 'R':\n",
    "        return pd.Series(np.append(row.fillna(0).values, 'R'))\n",
    "    return row\n",
    "\n",
    "# Apply the function to each row\n",
    "# df_padded = df.apply(pad_row, axis=1)\n",
    "\n",
    "# # Set pandas display option to show all rows\n",
    "# # pd.set_option('display.max_rows', None)\n",
    "\n",
    "# # Print the DataFrame\n",
    "# print(df_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract edge indices\n",
    "edge_index = torch.tensor(df[['Node', 'Edge']].values, dtype=torch.long)\n",
    "\n",
    "# # Extract node features (assuming features are in columns 'feature1', 'feature2', ..., 'featureN')\n",
    "node_features = torch.tensor(df[['Data1','Data2','Data3','Data4','Data5','Data6','Data7','Data8',]].values, dtype=torch.float)\n",
    "\n",
    "y = torch.tensor(df['label'], dtype=torch.long)\n",
    "# # Create a Data object\n",
    "data = Data(x=node_features, edge_index=edge_index, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[4580224, 8], edge_index=[4580224, 2], y=[4580224])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''' From GitHub Copilot\n",
    "Key Attributes of the Data Class:\n",
    "x: Node feature matrix with shape [num_nodes, num_node_features]. Each row corresponds to the feature vector of a node.\n",
    "edge_index: Graph connectivity in COO format with shape [2, num_edges]. Each column represents an edge between two nodes.\n",
    "edge_attr (optional): Edge feature matrix with shape [num_edges, num_edge_features]. Each row corresponds to the feature vector of an edge.\n",
    "y (optional): Graph-level or node-level labels.\n",
    "pos (optional): Node position matrix with shape [num_nodes, num_dimensions]. Useful for visualization or spatial graphs.\n",
    "batch (optional): Batch vector, which assigns each node to a specific graph in a mini-batch.\n",
    "'''\n",
    "# label logic - if T in window then label is 1, else 0. Start simple and build out from there\n",
    "# x = [# nodes, # features], for my case [200, 10]\n",
    "# edge_index = [2, # edges], for my case [2, 199]\n",
    "# y = [# nodes, # labels], for my case [200, 1]\n",
    "arr = df[['CAN ID', 'Node', 'Edge']].to_numpy()\n",
    "# maybe a stride of 25 to speed up the process?? At least to start\n",
    "# stride of 1 was over 10 GBs, so will increase to 25\n",
    "dataset = TimeSeriesGraphDataset(arr, window_size=50, stride=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'../datasets/dataset_rpms_25.pt'\n",
    "torch.save(dataset, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TimeSeriesGraphDataset' object has no attribute '_indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\User1\\miniconda3\\envs\\dfl\\lib\\site-packages\\IPython\\core\\formatters.py:770\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    763\u001b[0m stream \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[0;32m    764\u001b[0m printer \u001b[38;5;241m=\u001b[39m pretty\u001b[38;5;241m.\u001b[39mRepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewline,\n\u001b[0;32m    766\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_seq_length,\n\u001b[0;32m    767\u001b[0m     singleton_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingleton_printers,\n\u001b[0;32m    768\u001b[0m     type_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_printers,\n\u001b[0;32m    769\u001b[0m     deferred_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeferred_printers)\n\u001b[1;32m--> 770\u001b[0m \u001b[43mprinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    771\u001b[0m printer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32mc:\\Users\\User1\\miniconda3\\envs\\dfl\\lib\\site-packages\\IPython\\lib\\pretty.py:419\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    408\u001b[0m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[0;32m    409\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    410\u001b[0m                     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\n\u001b[0;32m    411\u001b[0m                     \u001b[38;5;66;03m# check if cls defines __repr__\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m                     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(_safe_getattr(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    418\u001b[0m                 ):\n\u001b[1;32m--> 419\u001b[0m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\User1\\miniconda3\\envs\\dfl\\lib\\site-packages\\IPython\\lib\\pretty.py:794\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[1;34m(obj, p, cycle)\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[1;32m--> 794\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    795\u001b[0m lines \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgroup():\n",
      "File \u001b[1;32mc:\\Users\\User1\\miniconda3\\envs\\dfl\\lib\\site-packages\\torch_geometric\\data\\dataset.py:364\u001b[0m, in \u001b[0;36mDataset.__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m--> 364\u001b[0m     arg_repr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_repr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\User1\\miniconda3\\envs\\dfl\\lib\\site-packages\\torch_geometric\\data\\dataset.py:274\u001b[0m, in \u001b[0;36mDataset.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"The number of examples in the dataset.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\User1\\miniconda3\\envs\\dfl\\lib\\site-packages\\torch_geometric\\data\\dataset.py:118\u001b[0m, in \u001b[0;36mDataset.indices\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mindices\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence:\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlen()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TimeSeriesGraphDataset' object has no attribute '_indices'"
     ]
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TimeSeriesGraphDataset' object has no attribute '_indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 33\u001b[0m\n\u001b[0;32m     24\u001b[0m test_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Calculate the number of samples for training and testing\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# num_samples = len(dataset)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# num_train = int(train_ratio * num_samples)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Split the dataset\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# train_dataset, test_dataset = random_split(dataset, [num_train, num_test])\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\u001b[39;00m\n\u001b[0;32m     36\u001b[0m model \u001b[38;5;241m=\u001b[39m AnomalyGNN(num_node_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, hidden_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User1\\miniconda3\\envs\\dfl\\lib\\site-packages\\torch_geometric\\loader\\dataloader.py:87\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, follow_batch, exclude_keys, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_batch \u001b[38;5;241m=\u001b[39m follow_batch\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexclude_keys \u001b[38;5;241m=\u001b[39m exclude_keys\n\u001b[1;32m---> 87\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     88\u001b[0m     dataset,\n\u001b[0;32m     89\u001b[0m     batch_size,\n\u001b[0;32m     90\u001b[0m     shuffle,\n\u001b[0;32m     91\u001b[0m     collate_fn\u001b[38;5;241m=\u001b[39mCollater(dataset, follow_batch, exclude_keys),\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     93\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\User1\\miniconda3\\envs\\dfl\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:350\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 350\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User1\\miniconda3\\envs\\dfl\\lib\\site-packages\\torch\\utils\\data\\sampler.py:142\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement, \u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_samples\u001b[49m, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\User1\\miniconda3\\envs\\dfl\\lib\\site-packages\\torch\\utils\\data\\sampler.py:149\u001b[0m, in \u001b[0;36mRandomSampler.num_samples\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnum_samples\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;66;03m# dataset size might change at runtime\u001b[39;00m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 149\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_samples\n",
      "File \u001b[1;32mc:\\Users\\User1\\miniconda3\\envs\\dfl\\lib\\site-packages\\torch_geometric\\data\\dataset.py:274\u001b[0m, in \u001b[0;36mDataset.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"The number of examples in the dataset.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\User1\\miniconda3\\envs\\dfl\\lib\\site-packages\\torch_geometric\\data\\dataset.py:118\u001b[0m, in \u001b[0;36mDataset.indices\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mindices\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Sequence:\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlen()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TimeSeriesGraphDataset' object has no attribute '_indices'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "class AnomalyGNN(nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels):\n",
    "        super(AnomalyGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.classifier = nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)  # Aggregate node features\n",
    "        return self.classifier(x).squeeze()\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "dataset = dataset\n",
    "# Define the split ratio\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "# Calculate the number of samples for training and testing\n",
    "# num_samples = len(dataset)\n",
    "# num_train = int(train_ratio * num_samples)\n",
    "# num_test = num_samples - num_train\n",
    "\n",
    "# Split the dataset\n",
    "# train_dataset, test_dataset = random_split(dataset, [num_train, num_test])\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model = AnomalyGNN(num_node_features=50, hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        predictions = torch.sigmoid(model(batch.x, batch.edge_index))\n",
    "        anomalies = predictions > 0.5  # Binary classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dfl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
