{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\User1\\\\Documents\\\\GitHub\\\\CAN-Graph\\\\notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # Successfully installed numpy-1.23.5\n",
    "import pandas as pd # Successfully installed pandas-1.3.5\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "# the temporal package is not available TODO: find what the issue is\n",
    "# from torch_geometric_temporal.nn.recurrent import A3TGCN2 # torch-geometric-temporal 0.54.0 requires pandas<=1.3.5, but you have pandas 2.2.3 which is incompatible.\n",
    "#from torch_geometric_temporal.signal import temporal_signal_split\n",
    "# import \n",
    "# Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
    "# from stellargraph import StellarGraph\n",
    "# import custom functions from utils.py\n",
    "# from utils import *\n",
    "os.getcwd() # double check current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .. goes up one level in directory\n",
    "path = r'../datasets/Car-Hacking Dataset/Fuzzy_dataset.csv'\n",
    "path = r'../datasets/Car-Hacking Dataset/DoS_dataset.csv'\n",
    "path = r'../datasets/Car-Hacking Dataset/gear_dataset.csv'\n",
    "path = r'../datasets/Car-Hacking Dataset/RPM_dataset.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.columns = ['Timestamp', 'CAN ID','DLC','Data1','Data2','Data3','Data4','Data5','Data6','Data7','Data8', 'label'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTemporal graph dataset: a graph that changes over time\\nGraph type: Homogeneous graph\\nNodes: CAN ID\\nEdges: The next CAN ID in the sequence\\nNode Features (optional): The data in the CAN ID\\n\\nSteps:\\n1. identify node properties\\n2. Edges: How to connect nodes?\\n3. Extract labels\\n\\nConvert to pytorch geometric format\\nOne graph to another graph: 200 messages to 1 graph\\n\\nThere is also pytorch geometric temporal package\\n\\n# build a baseline model RF, SVM, etc\\n\\n# fraud datasets may have incorrect labels -> use label smoothing\\nFeatureless nodes: use random numbers\\n\\nmake a GCN that uses labels only, and one that takes an average of data form its neighbors as well\\nGraph Attention Networks (GAT)\\n\\nIdea: could I use FL on the different car datasets, share those weights and perhaps it could generalize better. A practical use case would be between different companies, where they don't want to share their data\\nbut it is in their best interest to have the best performing cybersecurity model.\\n\\nhttps://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.explain.algorithm.GNNExplainer.html\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Temporal graph dataset: a graph that changes over time\n",
    "Graph type: Homogeneous graph\n",
    "Nodes: CAN ID\n",
    "Edges: The next CAN ID in the sequence\n",
    "Node Features (optional): The data in the CAN ID\n",
    "\n",
    "Steps:\n",
    "1. identify node properties\n",
    "2. Edges: How to connect nodes?\n",
    "3. Extract labels\n",
    "\n",
    "Convert to pytorch geometric format\n",
    "One graph to another graph: 200 messages to 1 graph\n",
    "\n",
    "There is also pytorch geometric temporal package\n",
    "\n",
    "# build a baseline model RF, SVM, etc\n",
    "\n",
    "# fraud datasets may have incorrect labels -> use label smoothing\n",
    "Featureless nodes: use random numbers\n",
    "\n",
    "make a GCN that uses labels only, and one that takes an average of data form its neighbors as well\n",
    "Graph Attention Networks (GAT)\n",
    "\n",
    "Idea: could I use FL on the different car datasets, share those weights and perhaps it could generalize better. A practical use case would be between different companies, where they don't want to share their data\n",
    "but it is in their best interest to have the best performing cybersecurity model.\n",
    "\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.explain.algorithm.GNNExplainer.html\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Node'] = df['CAN ID']\n",
    "df['Edge'] = df['CAN ID'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_decimal(x):\n",
    "    if x is None or x == 'None':\n",
    "        return None\n",
    "    try:\n",
    "        return int(x, 16)\n",
    "    except (ValueError, TypeError):\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the last row\n",
    "df_dropped_last_row = df.drop(df.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hex_to_decimal = lambda y: int(y, 16)\n",
    "# Need to encode the strings to integers\n",
    "specific_id_can_data_int = df.apply(lambda x: x.apply(hex_to_decimal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(window_data, edge_index):\n",
    "    x = torch.tensor(window_data, dtype=torch.float)\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "class TimeSeriesGraphDataset(Dataset):\n",
    "    def __init__(self, time_series_data, window_size, stride):\n",
    "        self.data = time_series_data\n",
    "        self.window_size = window_size\n",
    "        self.stride = stride\n",
    "        self.graphs = self._create_graphs()\n",
    "\n",
    "    def _create_graphs(self):\n",
    "        graphs = []\n",
    "        for i in range(0, len(self.data) - self.window_size + 1, self.stride):\n",
    "            window = self.data[i:i+self.window_size]\n",
    "            #print(window)\n",
    "            graph = create_graph(window, self._get_edge_index(window[:, -1]))\n",
    "            graphs.append(graph)\n",
    "        return graphs\n",
    "\n",
    "    def _get_edge_index(self, edge_data: np.ndarray) -> torch.Tensor:\n",
    "        # Create edges based on the last column data\n",
    "        edges = []\n",
    "        for i, value in enumerate(edge_data):\n",
    "            # Convert the edge value to an integer index\n",
    "            target = int(value)\n",
    "            if 0 <= target < len(edge_data):  # Ensure the target is within valid range\n",
    "                edges.append([i, target])\n",
    "        \n",
    "        # If no valid edges, create a self-loop to avoid errors\n",
    "        if not edges:\n",
    "            edges = [[0, 0]]\n",
    "        \n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "        return edge_index\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.graphs)\n",
    "\n",
    "    def get(self, idx):\n",
    "        return self.graphs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = df_dropped_last_row[['CAN ID', 'Node', 'Edge']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract edge indices\n",
    "edge_index = torch.tensor(df[['Node', 'Edge']].values, dtype=torch.long)\n",
    "\n",
    "# # Extract node features (assuming features are in columns 'feature1', 'feature2', ..., 'featureN')\n",
    "node_features = torch.tensor(df[['Data1','Data2','Data3','Data4','Data5','Data6','Data7','Data8',]].values, dtype=torch.float)\n",
    "\n",
    "y = torch.tensor(node_labels, dtype=torch.long)\n",
    "# # Create a Data object\n",
    "data = Data(x=node_features, edge_index=edge_index, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"' From GitHub Copilot\\nKey Attributes of the Data Class:\\nx: Node feature matrix with shape [num_nodes, num_node_features]. Each row corresponds to the feature vector of a node.\\nedge_index: Graph connectivity in COO format with shape [2, num_edges]. Each column represents an edge between two nodes.\\nedge_attr (optional): Edge feature matrix with shape [num_edges, num_edge_features]. Each row corresponds to the feature vector of an edge.\\ny (optional): Graph-level or node-level labels.\\npos (optional): Node position matrix with shape [num_nodes, num_dimensions]. Useful for visualization or spatial graphs.\\nbatch (optional): Batch vector, which assigns each node to a specific graph in a mini-batch.\\n\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''' From GitHub Copilot\n",
    "Key Attributes of the Data Class:\n",
    "x: Node feature matrix with shape [num_nodes, num_node_features]. Each row corresponds to the feature vector of a node.\n",
    "edge_index: Graph connectivity in COO format with shape [2, num_edges]. Each column represents an edge between two nodes.\n",
    "edge_attr (optional): Edge feature matrix with shape [num_edges, num_edge_features]. Each row corresponds to the feature vector of an edge.\n",
    "y (optional): Graph-level or node-level labels.\n",
    "pos (optional): Node position matrix with shape [num_nodes, num_dimensions]. Useful for visualization or spatial graphs.\n",
    "batch (optional): Batch vector, which assigns each node to a specific graph in a mini-batch.\n",
    "\n",
    "\n",
    "'''\n",
    "# label logic - if T in window then label is 1, else 0. Start simple and build out from there\n",
    "# x = [# nodes, # features], for my case [200, 10]\n",
    "# edge_index = [2, # edges], for my case [2, 199]\n",
    "# y = [# nodes, # labels], for my case [200, 1]\n",
    "\n",
    "#dataset = TimeSeriesGraphDataset(arr, window_size=50, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class AnomalyGNN(nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_channels):\n",
    "        super(AnomalyGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.classifier = nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)  # Aggregate node features\n",
    "        return self.classifier(x).squeeze()\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dataset = TimeSeriesGraphDataset(time_series_data, window_size=50, stride=1)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model = AnomalyGNN(num_node_features=50, hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        predictions = torch.sigmoid(model(batch.x, batch.edge_index))\n",
    "        anomalies = predictions > 0.5  # Binary classification threshold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dfl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
